{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uninstall all previous versions of cupy that may conflict\n",
        "!pip uninstall -y cupy-cuda11x cupy-cuda12x cupy\n",
        "\n",
        "# Install compatible version for Colab's CUDA (11.x)\n",
        "!pip install -q cupy-cuda11x\n",
        "\n",
        "import cupy as cp\n",
        "try:\n",
        "    print(\"GPU name:\", cp.cuda.runtime.getDeviceProperties(0)['name'].decode())\n",
        "    print(\"✅ GPU is available and working with CuPy.\")\n",
        "except cp.cuda.runtime.CUDARuntimeError as e:\n",
        "    print(\"❌ GPU not available or driver issue:\", e)\n",
        "\n",
        " If you see GPU not available, do this:\n",
        "Go to Runtime > Change runtime type\n",
        "\n",
        "Set Hardware accelerator: GPU\n",
        "\n",
        "Click Save\n",
        "\n",
        "Restart runtime after setting GPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnvTOodtq41r",
        "outputId": "8e95c55f-2826-4a6d-9f24-3db3aebbafa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mGPU name: Tesla T4\n",
            "✅ GPU is available and working with CuPy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "r00aA7NVrusa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix size\n",
        "N, M, K = 128, 128, 128  # You can change these values\n",
        "\n",
        "# Random input matrices on CPU\n",
        "A_cpu = np.random.randint(0, 100, size=(N, K)).astype(np.float32)\n",
        "B_cpu = np.random.randint(0, 100, size=(K, M)).astype(np.float32)\n",
        "\n",
        "# CPU matrix multiplication\n",
        "C_cpu = A_cpu @ B_cpu\n",
        "\n",
        "# Print input matrices\n",
        "print(\"Matrix A:\")\n",
        "print(A_cpu)\n",
        "print(\"\\nMatrix B:\")\n",
        "print(B_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXgRf6-Er2R6",
        "outputId": "669339af-0ec5-48d1-b6ef-2d8ee3d1494f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "[[28. 30. 34. ... 29. 66. 71.]\n",
            " [15. 40. 27. ... 88. 76. 83.]\n",
            " [91.  0. 75. ... 60. 90. 84.]\n",
            " ...\n",
            " [82. 75. 45. ... 62. 69. 37.]\n",
            " [30. 16. 88. ... 17. 19. 39.]\n",
            " [74. 33. 53. ... 38. 67. 79.]]\n",
            "\n",
            "Matrix B:\n",
            "[[66. 43. 54. ... 75. 55. 21.]\n",
            " [90. 22. 80. ... 57. 11. 84.]\n",
            " [27. 36. 31. ... 13. 86. 25.]\n",
            " ...\n",
            " [ 7. 12. 64. ...  5.  8. 83.]\n",
            " [12.  7. 34. ... 39. 53. 30.]\n",
            " [94. 54. 16. ... 92. 61. 96.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer to GPU\n",
        "A_gpu = cp.array(A_cpu)\n",
        "B_gpu = cp.array(B_cpu)\n",
        "\n",
        "# Time GPU multiplication\n",
        "start = cp.cuda.Event()\n",
        "end = cp.cuda.Event()\n",
        "start.record()\n",
        "\n",
        "C_gpu = A_gpu @ B_gpu\n",
        "\n",
        "end.record()\n",
        "end.synchronize()\n",
        "gpu_time = cp.cuda.get_elapsed_time(start, end)\n",
        "\n",
        "# Bring result back to CPU\n",
        "C_result = cp.asnumpy(C_gpu)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nCPU Result (C = A @ B):\")\n",
        "print(C_cpu)\n",
        "print(\"\\nGPU Result:\")\n",
        "print(C_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLpga54Nr3Hz",
        "outputId": "3e80c027-6fe3-451c-9590-247c27aea065"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU Result (C = A @ B):\n",
            "[[309028. 316748. 321881. ... 301639. 313374. 319015.]\n",
            " [280164. 312020. 308720. ... 272032. 284370. 311517.]\n",
            " [308866. 295653. 303233. ... 313308. 317096. 316020.]\n",
            " ...\n",
            " [322095. 335452. 344794. ... 334664. 328340. 328364.]\n",
            " [286842. 306860. 285753. ... 283615. 290674. 285059.]\n",
            " [331694. 319110. 325290. ... 327280. 330593. 328361.]]\n",
            "\n",
            "GPU Result:\n",
            "[[309028. 316748. 321881. ... 301639. 313374. 319015.]\n",
            " [280164. 312020. 308720. ... 272032. 284370. 311517.]\n",
            " [308866. 295653. 303233. ... 313308. 317096. 316020.]\n",
            " ...\n",
            " [322095. 335452. 344794. ... 334664. 328340. 328364.]\n",
            " [286842. 306860. 285753. ... 283615. 290674. 285059.]\n",
            " [331694. 319110. 325290. ... 327280. 330593. 328361.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total error (sum of element-wise differences)\n",
        "total_error = np.sum(C_result - C_cpu)\n",
        "print(f\"\\nTotal Error: {total_error:.6f}\")\n",
        "print(f\"Time Elapsed on GPU (ms): {gpu_time:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5f3Rcwyr9qt",
        "outputId": "daf9f0c7-8da2-4199-e4f5-72ae26d632e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Error: 0.000000\n",
            "Time Elapsed on GPU (ms): 0.5437\n"
          ]
        }
      ]
    }
  ]
}